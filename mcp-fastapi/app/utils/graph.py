from typing import List, Dict, Any, TypedDict, Union, Optional
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.agents import AgentFinish, AgentAction
from langchain.agents.format_scratchpad import format_to_openai_function_messages
from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser
from langchain_core.tools import BaseTool
from langgraph.graph import StateGraph, END
import asyncio
import json
import re

from .mcp_tools import available_tools
from .llm import get_llm


# ìƒíƒœ ì •ì˜
class AgentState(TypedDict):
    messages: List[Union[HumanMessage, AIMessage]]
    next: str
    # ì¶”ê°€
    loop_count: int


def build_initial_state(user_input: str) -> AgentState:
    """ì´ˆê¸° ìƒíƒœ ìƒì„±"""
    return AgentState(
        messages=[HumanMessage(content=user_input)],
        next="llm",
        # ì¶”ê°€
        loop_count=0
    )

def extract_last_json_block(text: str) -> Optional[str]:
    # LLMì€ ```json``` ë¸”ëŸ­ í˜•íƒœë¥¼ ì¸ì‹ì„ ì˜í•¨. í”„ë¡¬í”„íŠ¸ì— ê¼­ ë„£ì–´ì£¼ì„¸ìš”. ê·¸ëƒ¥ jsonìœ¼ë¡œ ì¨ë‹¬ë¼ê³  í•˜ë©´ ì¸ì‹ì´ ì˜ ì•ˆë¨
    try:
        matches = re.findall(r"```json\s*(\{.*?\})\s*```", text, re.DOTALL)
        if matches:
            return matches[-1]  # ë§ˆì§€ë§‰ JSON ë¸”ëŸ­
    except Exception as e:
        print(f"JSON extract error: {e}")
    return None


class ExaOneOutputParser:
    """ExaOne ì¶œë ¥ì„ íŒŒì‹±í•˜ëŠ” í´ë˜ìŠ¤"""
    
    # def parse(self, text: str) -> Union[AgentAction, AgentFinish]:
    #     """ExaOne ì‘ë‹µì„ AgentAction ë˜ëŠ” AgentFinishë¡œ íŒŒì‹±"""
    #     try:
    #         json_str = extract_last_json_block(text)
    #         if json_str:
    #             data = json.loads(json_str)

    #             # ğŸ‘‡ ì´ ë¶€ë¶„ ì¶”ê°€: ê²°ê³¼ ì„¤ëª…ì´ í¬í•¨ë¼ ìˆìœ¼ë©´ AgentFinishë¡œ ê°„ì£¼
    #             if "name" in data and "arguments" in data:
    #                 if "result" in text.lower() or "final" in text.lower():
    #                     return AgentFinish(
    #                         return_values={"output": text},
    #                         log=text
    #                     )
    #                 return AgentAction(
    #                     tool=data["name"],
    #                     tool_input=data["arguments"],
    #                     log=text
    #                 )
    #         return AgentFinish(
    #             return_values={"output": text},
    #             log=text
    #         )
    #     except Exception as e:
    #         print(f"Parsing error: {e}")
    #         print(f"Failed to parse text: {text}")
    #         return AgentFinish(
    #             return_values={"output": text},
    #             log=text
    #         )
    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:
        print("text : ",text)
        json_str = extract_last_json_block(text)
        if json_str:
            try:
                data = json.loads(json_str)
                if "result" in data:
                    return AgentFinish(return_values={"output": data["result"]}, log=text)
                elif "name" in data and "arguments" in data:
                    return AgentAction(tool=data["name"], tool_input=data["arguments"], log=text)
            except json.JSONDecodeError as e:
                print(f"[parse] JSON decode error: {e}")
        
        return AgentAction(tool="retry", tool_input={}, log=text)  # fallback



def create_agent_graph():
    """LangGraph ê¸°ë°˜ ì—ì´ì „íŠ¸ ìƒì„±"""
    llm = get_llm()

    def get_next_step(state: AgentState) -> str:
        """ë‹¤ìŒ ë‹¨ê³„ ê²°ì •"""

        if state["loop_count"] > 3:
            return "end"
        return state["next"]

    async def call_llm(state: AgentState) -> Dict[str, AgentState]:
        """LLM í˜¸ì¶œ"""
        messages = state["messages"]
        
        # ë©”ì‹œì§€ì™€ ë„êµ¬ ì •ë³´ í¬ë§·íŒ…
        formatted_messages = []
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
        tools_description = "\n".join([
            f"{tool.name}: {tool.description}" 
            for tool in available_tools
        ])
#         formatted_messages.append(HumanMessage(content=f"""Tools: {tools_description}
# Format: {{"name": "tool_name", "arguments": {{"arg1": "value1"}}}}"""))
        if not any("Tools:" in msg.content for msg in messages):
            formatted_messages.append(HumanMessage(content=f"""Tools: {tools_description}
            Format:
            ```json
            {{"name": "tool_name", "arguments": {{"arg1": "value1"}}}}
            ```
            Please strictly follow the format above and return a valid JSON object inside a json code block (```json). The "name" must be the tool name, and "arguments" must contain the input parameters."""))
            

        # ì‚¬ìš©ì ë©”ì‹œì§€ì™€ ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶”ê°€
        formatted_messages.extend(messages)

        # ExaOne LLM í˜¸ì¶œ
        messages_text = "\n".join([msg.content for msg in formatted_messages])
        
        try:
            response = await llm.generate(messages_text)
        except Exception as e:
            print(f"Generation error: {e}")
            response = "I apologize, but I couldn't process that request."

        # ExaOne ì „ìš© íŒŒì„œ ì‚¬ìš©
        parser = ExaOneOutputParser()
        parsed_response = parser.parse(response)

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        new_messages = messages + [AIMessage(
            content=response,
            additional_kwargs={"action": parsed_response}
        )]

        # AgentStateë¥¼ ì§ì ‘ ë°˜í™˜
        next_step = "end" if isinstance(parsed_response, AgentFinish) else "tools"
        
        # TypedDictë¥¼ ì§ì ‘ ìƒì„±
        new_state = AgentState(
            messages=new_messages,
            next=next_step,
            loop_count=state["loop_count"] + 1
        )
        
        return new_state
    
    async def execute_tools(state_dict: Dict[str, Any]) -> Dict[str, Any]:
        """ë„êµ¬ ì‹¤í–‰"""
        messages = state_dict["messages"]
        last_message = messages[-1]

        new_messages = messages.copy()

        if isinstance(last_message, AIMessage):
            action = last_message.additional_kwargs.get("action")
            if action and not isinstance(action, AgentFinish):
                tool_name = action.tool
                tool_args = action.tool_input
                tool = next((t for t in available_tools if t.name == tool_name), None)

                if tool:
                    try:
                        # ë„êµ¬ ì‹¤í–‰ (ë¹„ë™ê¸°/ë™ê¸° ëŒ€ì‘)
                        if asyncio.iscoroutinefunction(tool.invoke):
                            result = await tool.invoke(tool_args)
                        else:
                            result = tool.invoke(tool_args)

                        # ê²°ê³¼ë¥¼ ë©”ì‹œì§€ë¡œ ì¶”ê°€
                        # new_messages.append(HumanMessage(content=f"The result of {tool_name} is '{str(result)}'. Please summarize the final answer in a user-friendly sentence."))
                        new_messages.append(
                            HumanMessage(
                                content=f"The result of {tool_name} is '{str(result)}'. "
                                    "Is this a final and appropriate answer? If yes, return it in the following JSON format:\n\n"
                                    "```json\n"
                                    '{"result": "The final answer you would say directly to the user."}\n'
                                    "```\n"
                                    "If not, think again and select another tool to try."
                            )
                        )
                        
                        # ë„êµ¬ ì‹¤í–‰ ì„±ê³µ ì‹œ LLMìœ¼ë¡œ ëŒì•„ê°€ê¸°
                        return AgentState(
                            messages=new_messages,
                            next="llm"
                        )
                    except Exception as e:
                        # ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ê°€í•˜ê³  ì¢…ë£Œ
                        new_messages.append(HumanMessage(content=f"Error executing tool: {str(e)}"))
                        return AgentState(
                            messages=new_messages,
                            next="end"
                        )

        # ë„êµ¬ ì‹¤í–‰ì´ ë¶ˆí•„ìš”í•˜ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš° ì¢…ë£Œ
        return AgentState(
            messages=new_messages,
            next="end"
        )

    # LangGraph ì›Œí¬í”Œë¡œ ì •ì˜
    workflow = StateGraph(state_schema=AgentState)

    # ë…¸ë“œ ì •ì˜
    workflow.add_node("llm", call_llm)
    workflow.add_node("tools", execute_tools)

    # ì‹œì‘ ë…¸ë“œ ì„¤ì •
    workflow.set_entry_point("llm")

    # ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì„¤ì •
    workflow.add_conditional_edges(
        "llm",
        get_next_step,
        {
            "tools": "tools",
            "end": END
        }
    )
    workflow.add_conditional_edges(
        "tools",
        get_next_step,
        {
            "llm": "llm",
            "end": END
        }
    )

    return workflow.compile()


async def process_with_graph(input_data: Dict[str, str]) -> str:
    """LangGraph ì—ì´ì „íŠ¸ ì‹¤í–‰"""
    chain = create_agent_graph()
    
    # ì´ˆê¸° ìƒíƒœ ìƒì„±
    initial_state = build_initial_state(input_data["input"])
    
    # StateGraphì— ìƒíƒœ ì§ì ‘ ì „ë‹¬
    result = await chain.ainvoke(initial_state)
    print(result)
    
    # ìµœì¢… ë©”ì‹œì§€ ë°˜í™˜
    final_message = result["messages"][-1]
    return final_message.content