#!/usr/bin/env python3
"""
RAG System Test Script

This script demonstrates the RAG system functionality with example
document ingestion and querying operations.
"""

import asyncio
import json
import logging
from app.rag_tool import rag_tool

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# Sample documents for testing
SAMPLE_DOCUMENTS = [
    {
        "title": "ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ",
        "language": "ko",
        "source": "AI êµìœ¡ ìë£Œ",
        "text": """
        ì¸ê³µì§€ëŠ¥(AI)ì€ ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ë„ë¡ ì„¤ê³„ëœ ê¸°ìˆ ì…ë‹ˆë‹¤. 
        ë¨¸ì‹ ëŸ¬ë‹ì€ AIì˜ í•˜ìœ„ ë¶„ì•¼ë¡œ, ë°ì´í„°ì—ì„œ íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        ë”¥ëŸ¬ë‹ì€ ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ë°©ë²•ìœ¼ë¡œ, ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤.
        ìì—°ì–´ ì²˜ë¦¬(NLP)ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” AI ê¸°ìˆ ì…ë‹ˆë‹¤.
        ì»´í“¨í„° ë¹„ì „ì€ ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ë¥¼ ë¶„ì„í•˜ê³  ì´í•´í•˜ëŠ” AI ê¸°ìˆ ì…ë‹ˆë‹¤.
        """
    },
    {
        "title": "Machine Learning Fundamentals",
        "language": "en",
        "source": "ML Tutorial",
        "text": """
        Machine Learning is a subset of artificial intelligence that enables computers to learn
        and make decisions from data without being explicitly programmed for every task.
        Supervised learning uses labeled data to train models that can make predictions on new data.
        Unsupervised learning finds patterns in data without labeled examples.
        Reinforcement learning learns through trial and error by receiving rewards or penalties.
        Deep learning uses neural networks with multiple layers to model complex patterns.
        """
    },
    {
        "title": "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹å…¥é–€",
        "language": "ja",
        "source": "Data Science Guide",
        "text": """
        ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¾¡å€¤ã®ã‚ã‚‹æ´å¯Ÿã‚’æŠ½å‡ºã™ã‚‹å­¦éš›çš„ãªåˆ†é‡ã§ã™ã€‚
        çµ±è¨ˆå­¦ã€æ©Ÿæ¢°å­¦ç¿’ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®çŸ¥è­˜ãŒå¿…è¦ã§ã™ã€‚
        ãƒ‡ãƒ¼ã‚¿ã®åé›†ã€ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã€åˆ†æã€å¯è¦–åŒ–ãŒä¸»ãªå·¥ç¨‹ã§ã™ã€‚
        Pythonã‚„Rãªã©ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªãŒã‚ˆãä½¿ã‚ã‚Œã¾ã™ã€‚
        ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ã«ã¯Hadoopã‚„Sparkãªã©ã®ãƒ„ãƒ¼ãƒ«ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
        """
    }
]

# Test queries in different languages
TEST_QUERIES = [
    "ë¨¸ì‹ ëŸ¬ë‹ì´ ë¬´ì—‡ì¸ê°€ìš”?",
    "What is deep learning?",
    "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
    "ìì—°ì–´ ì²˜ë¦¬ì˜ ìš©ë„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
    "How does supervised learning work?",
    "ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ"
]


async def test_document_ingestion():
    """Test document ingestion functionality."""
    print("\n" + "="*60)
    print("ğŸ”„ Testing Document Ingestion")
    print("="*60)
    
    ingested_docs = []
    
    for i, doc in enumerate(SAMPLE_DOCUMENTS):
        print(f"\nğŸ“„ Ingesting document {i+1}: {doc['title']}")
        
        request = {
            "action": "ingest",
            "text": doc["text"],
            "title": doc["title"],
            "source": doc["source"],
            "language": doc["language"],
            "chunking_method": "sentence"
        }
        
        try:
            result = await rag_tool._arun(json.dumps(request, ensure_ascii=False))
            result_data = json.loads(result)
            
            if result_data.get("success"):
                doc_id = result_data["document_id"]
                ingested_docs.append(doc_id)
                print(f"âœ… Successfully ingested: {doc_id}")
                
                # Print document info
                if "document_info" in result_data:
                    info = result_data["document_info"]
                    print(f"   ğŸ“Š Chunks: {info.get('chunk_count', 'N/A')}")
                    print(f"   ğŸ“… Created: {info.get('created_at', 'N/A')}")
            else:
                print(f"âŒ Failed to ingest document: {result_data.get('error', 'Unknown error')}")
                
        except Exception as e:
            print(f"âŒ Exception during ingestion: {e}")
    
    print(f"\nğŸ“ˆ Ingestion Summary: {len(ingested_docs)}/{len(SAMPLE_DOCUMENTS)} documents successfully ingested")
    return ingested_docs


async def test_document_listing():
    """Test document listing functionality."""
    print("\n" + "="*60)
    print("ğŸ“‹ Testing Document Listing")
    print("="*60)
    
    request = {
        "action": "list",
        "limit": 20,
        "offset": 0
    }
    
    try:
        result = await rag_tool._arun(json.dumps(request))
        result_data = json.loads(result)
        
        if result_data.get("success"):
            documents = result_data["documents"]
            print(f"ğŸ“š Found {len(documents)} documents:")
            
            for doc in documents:
                print(f"   ğŸ“„ {doc.get('title', 'Untitled')} ({doc.get('language', 'unknown')})")
                print(f"      ğŸ†” ID: {doc['document_id']}")
                print(f"      ğŸ“… Created: {doc.get('created_at', 'N/A')}")
                print()
        else:
            print(f"âŒ Failed to list documents: {result_data.get('error', 'Unknown error')}")
            
    except Exception as e:
        print(f"âŒ Exception during listing: {e}")


async def test_knowledge_queries():
    """Test knowledge base querying functionality."""
    print("\n" + "="*60)
    print("ğŸ” Testing Knowledge Base Queries")
    print("="*60)
    
    for i, query in enumerate(TEST_QUERIES):
        print(f"\nğŸ¤” Query {i+1}: {query}")
        print("-" * 50)
        
        request = {
            "action": "query",
            "query": query,
            "top_k": 3,
            "similarity_threshold": 0.3,
            "include_metadata": True
        }
        
        try:
            result = await rag_tool._arun(json.dumps(request, ensure_ascii=False))
            result_data = json.loads(result)
            
            if result_data.get("success"):
                context_chunks = result_data["context_chunks"]
                metadata = result_data["metadata"]
                
                print(f"ğŸ“Š Retrieved {len(context_chunks)} relevant chunks")
                print(f"â±ï¸  Processing time: {metadata.get('processing_time', 0):.3f}s")
                
                if context_chunks:
                    print("\nğŸ“– Retrieved Context:")
                    for j, chunk in enumerate(context_chunks):
                        score = chunk["similarity_score"]
                        title = chunk["metadata"].get("document_title", "Unknown")
                        text_preview = chunk["text"][:150] + "..." if len(chunk["text"]) > 150 else chunk["text"]
                        
                        print(f"   {j+1}. [{title}] (Score: {score:.3f})")
                        print(f"      {text_preview}")
                        print()
                    
                    # Show constructed prompt preview
                    prompt = result_data.get("answer_prompt", "")
                    if prompt:
                        prompt_preview = prompt[:300] + "..." if len(prompt) > 300 else prompt
                        print("ğŸ¯ Generated Prompt Preview:")
                        print(f"   {prompt_preview}")
                else:
                    print("âš ï¸  No relevant context found")
                    
            else:
                print(f"âŒ Query failed: {result_data.get('error', 'Unknown error')}")
                
        except Exception as e:
            print(f"âŒ Exception during query: {e}")


async def test_system_statistics():
    """Test system statistics functionality."""
    print("\n" + "="*60)
    print("ğŸ“Š Testing System Statistics")
    print("="*60)
    
    request = {"action": "stats"}
    
    try:
        result = await rag_tool._arun(json.dumps(request))
        result_data = json.loads(result)
        
        if result_data.get("success"):
            stats = result_data["stats"]
            
            print("ğŸ—ï¸  System Status:")
            print(f"   âœ… Initialized: {stats.get('initialized', False)}")
            
            if "vector_store" in stats:
                vs_stats = stats["vector_store"]
                print(f"   ğŸ“š Total Documents: {vs_stats.get('total_documents', 'N/A')}")
                print(f"   ğŸ“„ Total Chunks: {vs_stats.get('total_chunks', 'N/A')}")
                print(f"   ğŸ”¢ Embedding Dimension: {vs_stats.get('embedding_dimension', 'N/A')}")
            
            if "embedding_service" in stats:
                es_stats = stats["embedding_service"]
                print(f"   ğŸ¤– Embedding Model: {es_stats.get('model_name', 'N/A')}")
                print(f"   ğŸ’» Device: {es_stats.get('device', 'N/A')}")
                print(f"   ğŸŸ¢ Status: {es_stats.get('status', 'N/A')}")
                
            if "configuration" in stats:
                config = stats["configuration"]
                print("\nâš™ï¸  Configuration:")
                for key, value in config.items():
                    print(f"   {key}: {value}")
        else:
            print(f"âŒ Failed to get statistics: {result_data.get('error', 'Unknown error')}")
            
    except Exception as e:
        print(f"âŒ Exception during stats retrieval: {e}")


async def main():
    """Main test function."""
    print("ğŸš€ RAG System Comprehensive Test")
    print("=" * 80)
    print("This script will test all aspects of the RAG system:")
    print("1. Document ingestion with multilingual content")
    print("2. Document listing and management")
    print("3. Knowledge base querying in multiple languages")
    print("4. System statistics and health monitoring")
    print("=" * 80)
    
    try:
        # Test 1: Document Ingestion
        ingested_docs = await test_document_ingestion()
        
        # Test 2: Document Listing
        await test_document_listing()
        
        # Test 3: Knowledge Queries
        await test_knowledge_queries()
        
        # Test 4: System Statistics
        await test_system_statistics()
        
        print("\n" + "="*80)
        print("ğŸ‰ RAG System Test Completed!")
        print("="*80)
        print("âœ… All tests executed successfully")
        print("ğŸ“š The RAG system is ready for production use")
        print("ğŸ”§ Check the logs above for any issues or warnings")
        print("ğŸ“– Refer to RAG_README.md for detailed usage instructions")
        print("="*80)
        
    except Exception as e:
        print(f"\nâŒ Test execution failed: {e}")
        logger.exception("Test execution error")


if __name__ == "__main__":
    # Run the comprehensive test
    asyncio.run(main()) 